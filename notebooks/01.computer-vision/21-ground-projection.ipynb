{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rc(\"figure\", dpi=200)\n",
    "\n",
    "from dt_computer_vision.camera import CameraModel\n",
    "\n",
    "from dt_computer_vision.camera.calibration.extrinsics.boards import CalibrationBoard8by6\n",
    "from dt_computer_vision.ground_projection.rendering import debug_image\n",
    "from dt_computer_vision.ground_projection import GroundProjector\n",
    "\n",
    "from dt_computer_vision.ground_projection.types import GroundPoint\n",
    "from dt_computer_vision.camera import Pixel, NormalizedImagePoint\n",
    "\n",
    "from dt_computer_vision.line_detection import LineDetector, ColorRange, Detections\n",
    "from dt_computer_vision.line_detection.rendering import draw_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "this_dir: str = os.path.abspath('')\n",
    "assets_dir: str = os.path.join(this_dir, \"..\", \"..\", \"assets\", \"notebooks\", \"01.computer-vision\")\n",
    "image_fpath: str = os.path.join(assets_dir, f\"image0.jpg\")\n",
    "image_orig: np.ndarray = cv2.imread(image_fpath)\n",
    "board = CalibrationBoard8by6\n",
    "\n",
    "camera_properties = {\n",
    "    \"width\": 640,\n",
    "    \"height\": 480,\n",
    "    \"K\": [[295.79606866959824, 0.0, 321.2621599038631],\n",
    "          [0.0, 299.5389048862878, 241.73616515312332],\n",
    "          [0.0, 0.0, 1.0]],\n",
    "    \"D\": [-0.23543978771661125,\n",
    "          0.03637781479419574,\n",
    "          -0.0033069818601306755,\n",
    "          -0.0012140708179525926,\n",
    "          0.0],\n",
    "    \"P\": [[201.14027404785156, 0.0, 319.5586620845679, 0.0],\n",
    "          [0.0, 239.74398803710938, 237.60151004037834, 0.0],\n",
    "          [0.0, 0.0, 1.0, 0.0]],\n",
    "    # NOTE: this homography is computed in the 20-entrinsics-calibration jupyter notebook\n",
    "    \"H\": [[-2.42749970e-02, 9.46389079e-02, 3.81909422e-01],\n",
    "          [-4.55028567e-01, -1.17673909e-03, -1.87813039e-02],\n",
    "          [-1.46006785e-01, 3.29784838e+00, 1]]\n",
    "}\n",
    "\n",
    "assert image_orig.shape == (480, 640, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create camera\n",
    "camera = CameraModel(**camera_properties)\n",
    "projector = GroundProjector(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"red\": {\n",
    "        \"low_1\": [0, 140, 100],\n",
    "        \"high_1\": [15, 255, 255],\n",
    "        \"low_2\": [165, 140, 100],\n",
    "        \"high_2\": [180, 255, 255],\n",
    "    },\n",
    "    \"white\": {\n",
    "        \"low\": [0, 0, 150],\n",
    "        \"high\": [180, 100, 255]\n",
    "    },\n",
    "    \"yellow\": {\n",
    "        \"low\": [25, 140, 100],\n",
    "        \"high\": [45, 255, 255]\n",
    "    }\n",
    "}\n",
    "\n",
    "def detect_color(image: np.ndarray, color: str) -> Tuple[Detections, np.ndarray]:\n",
    "    detector: LineDetector = LineDetector()\n",
    "    color_range: ColorRange = ColorRange.fromDict(colors[color])\n",
    "    detections: Detections = detector.detect(image, [color_range])[0]\n",
    "    image0_dets = draw_segments(image, {color_range: detections})\n",
    "    return detections, image0_dets\n",
    "\n",
    "# detect segments\n",
    "color: str = \"white\"\n",
    "segments, image_w_detections = detect_color(image_orig, color)\n",
    "\n",
    "# draw segments\n",
    "image_w_detections = cv2.cvtColor(image_w_detections, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image_w_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# project segments onto the ground plane\n",
    "colored_segments = {\n",
    "    (255, 255, 255): []\n",
    "}\n",
    "\n",
    "for segment in segments.lines:\n",
    "    # distorted pixels\n",
    "    p0: Pixel = Pixel(segment[0], segment[1])\n",
    "    p1: Pixel = Pixel(segment[2], segment[3])\n",
    "    #print(p0)\n",
    "    # distorted pixels to rectified pixels\n",
    "    p0_rect: Pixel = camera.rectifier.rectify_pixel(p0)\n",
    "    p1_rect: Pixel = camera.rectifier.rectify_pixel(p1)\n",
    "    #print(p0_rect)\n",
    "    # rectified pixel to normalized coordinates\n",
    "    p0_norm: NormalizedImagePoint = camera.pixel2vector(p0_rect)\n",
    "    p1_norm: NormalizedImagePoint = camera.pixel2vector(p1_rect)\n",
    "    #print(p0_norm)\n",
    "    # project image point onto the ground plane\n",
    "    p0_ground: GroundPoint = projector.vector2ground(p0_norm)\n",
    "    p1_ground: GroundPoint = projector.vector2ground(p1_norm)\n",
    "    # print(p0)\n",
    "    # add grounded segment to output\n",
    "    colored_segments[(255, 255, 255)].append((p0_ground, p1_ground))\n",
    "\n",
    "image_w_projected_segments = debug_image(colored_segments, (300, 300))\n",
    "image_w_projected_segments = cv2.cvtColor(image_w_projected_segments, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image_w_projected_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# define cropping\n",
    "crop_x_amount = 0.5\n",
    "crop_y_amount = 0.5\n",
    "\n",
    "# create new camera parameters\n",
    "crop_x = int(image_orig.shape[1] * crop_x_amount)\n",
    "crop_y = int(image_orig.shape[0] * crop_y_amount)\n",
    "camera_params_orig = deepcopy(camera_properties)\n",
    "camera_params_cropped = deepcopy(camera_properties)\n",
    "camera_params_cropped[\"K\"][0][2] -= crop_x\n",
    "camera_params_cropped[\"K\"][1][2] -= crop_y\n",
    "\n",
    "# TODO: this should be using the rectified cx, cy instead\n",
    "camera_params_cropped[\"P\"][0][2] -= crop_x\n",
    "camera_params_cropped[\"P\"][1][2] -= crop_y\n",
    "\n",
    "# crop image\n",
    "image_cropped = image_orig[crop_y:, crop_x:, :]\n",
    "assert image_cropped.shape == (image_orig.shape[0] - crop_y, image_orig.shape[1] - crop_x, image_orig.shape[2])\n",
    "\n",
    "# update camera\n",
    "camera_cropped = CameraModel(**camera_params_cropped)\n",
    "projector_cropped = GroundProjector(camera_cropped)\n",
    "\n",
    "# detect segments\n",
    "color: str = \"white\"\n",
    "segments_cropped, image_w_detections_cropped = detect_color(image_cropped, color)\n",
    "\n",
    "# draw segments\n",
    "image_w_detections_cropped = cv2.cvtColor(image_w_detections_cropped, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image_w_detections_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# project segments onto the ground plane\n",
    "colored_segments_cropped = {\n",
    "    (255, 255, 255): []\n",
    "}\n",
    "\n",
    "for segment in segments_cropped.lines:\n",
    "    # distorted pixels\n",
    "    p0: Pixel = Pixel(segment[0], segment[1])\n",
    "    p1: Pixel = Pixel(segment[2], segment[3])\n",
    "    #print(p0)\n",
    "    # distorted pixels to rectified pixels\n",
    "    p0_rect: Pixel = camera_cropped.rectifier.rectify_pixel(p0)\n",
    "    p1_rect: Pixel = camera_cropped.rectifier.rectify_pixel(p1)\n",
    "    #print(p0_rect)\n",
    "    # rectified pixel to normalized coordinates\n",
    "    p0_norm: NormalizedImagePoint = camera_cropped.pixel2vector(p0_rect)\n",
    "    p1_norm: NormalizedImagePoint = camera_cropped.pixel2vector(p1_rect)\n",
    "    #print(p0_norm)\n",
    "    # project image point onto the ground plane\n",
    "    p0_ground: GroundPoint = projector_cropped.vector2ground(p0_norm)\n",
    "    p1_ground: GroundPoint = projector_cropped.vector2ground(p1_norm)\n",
    "    # print(p0)\n",
    "    # add grounded segment to output\n",
    "    colored_segments_cropped[(255, 255, 255)].append((p0_ground, p1_ground))\n",
    "\n",
    "image_w_projected_segments_cropped = debug_image(colored_segments_cropped, (300, 300))\n",
    "image_w_projected_segments_cropped = cv2.cvtColor(image_w_projected_segments_cropped, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image_w_projected_segments_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
