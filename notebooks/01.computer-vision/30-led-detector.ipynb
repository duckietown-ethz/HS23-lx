{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blob Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple, List\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rc(\"figure\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_IMG: int = 7\n",
    "\n",
    "this_dir: str = os.path.abspath('')\n",
    "assets_dir: str = os.path.join(this_dir, \"..\", \"..\", \"assets\", \"notebooks\", \"01.computer-vision\", \"blob-detector\", \"train\")\n",
    "image_glob_fpath: str = os.path.join(assets_dir, \"*.jpg\")\n",
    "image0_fpath: str = os.path.join(assets_dir, f\"{SAMPLE_IMG}.jpg\")\n",
    "\n",
    "all_images: List[str] = sorted(glob.glob(image_glob_fpath), key=lambda s: int(os.path.basename(s).split('.')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample: np.ndarray = cv2.imread(image0_fpath)\n",
    "plt.figure(figsize=(16, 9), dpi=96)\n",
    "rgb = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob Detector\n",
    "\n",
    "We are going to use the class `SimpleBlobDetector` from OpenCV to detect the blobs of light that the lit LEDs generate in the image. \n",
    "\n",
    "For further details about how this detector works internally, we suggest reading the [official documentation](https://docs.opencv.org/3.4/d0/d7a/classcv_1_1SimpleBlobDetector.html#details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters: dict = {\n",
    "    \"minThreshold\": 5,\n",
    "    \"maxThreshold\": 75,\n",
    "    \"thresholdStep\": 10,\n",
    "\n",
    "    # Filter by Area.\n",
    "    \"filterByArea\": True,\n",
    "    \"minArea\": (8 ** 2) * 3.14,    # min 8 pixels diameter\n",
    "    \"maxArea\": (64 ** 2) * 3.14,   # max 64 pixels diameter\n",
    "\n",
    "    # Filter by Circularity\n",
    "    \"filterByCircularity\": True,\n",
    "    \"minCircularity\": 0.7,\n",
    "\n",
    "    # Filter by Convexity\n",
    "    \"filterByConvexity\": True,\n",
    "    \"minConvexity\": 0.8,\n",
    "\n",
    "    # Filter by Inertia\n",
    "    \"filterByInertia\": False,\n",
    "    \"minInertiaRatio\": 0.05,\n",
    "}\n",
    "\n",
    "\n",
    "def extract_hsv(_bgr: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    _hsv = cv2.cvtColor(_bgr, cv2.COLOR_BGR2HSV)\n",
    "    _h = _hsv[:,:,0]\n",
    "    _s = _hsv[:,:,1]\n",
    "    _v = _hsv[:,:,2]\n",
    "    return _h, _s, _v\n",
    "\n",
    "\n",
    "def detect_blobs(_bgr: np.ndarray, **_params) -> Tuple[cv2.KeyPoint, ...]:\n",
    "    # create new configuration that extends the default\n",
    "    _cfg = cv2.SimpleBlobDetector_Params()\n",
    "    for _k, _v in chain(default_parameters.items(), _params.items()):\n",
    "        setattr(_cfg, _k, _v)\n",
    "    # create detector\n",
    "    _detector = cv2.SimpleBlobDetector.create(_cfg)\n",
    "    # find blobs\n",
    "    _keypoints = _detector.detect(_bgr)\n",
    "    print(f\"Found {len(_keypoints)} blobs\")\n",
    "    return _keypoints\n",
    "\n",
    "\n",
    "def draw_blobs(_bgr: np.ndarray, _blobs: Tuple[cv2.KeyPoint, ...]) -> np.ndarray:\n",
    "    # draw blobs on the original image\n",
    "    _bgr1 = copy.deepcopy(_bgr)\n",
    "    for kp in _blobs:\n",
    "        _bgr1 = cv2.circle(_bgr1, tuple(map(int, kp.pt)), int(kp.size), (0, 255, 0), 3)\n",
    "    return _bgr1\n",
    "\n",
    "\n",
    "def show_image(_bgr: np.ndarray, _title: str = \"ND\"):\n",
    "    # show image with superimposed blobs\n",
    "    plt.figure(figsize=(16, 9), dpi=96)\n",
    "    _rgb = cv2.cvtColor(_bgr, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(_rgb)\n",
    "    plt.title(f'Image: {_title}')\n",
    "\n",
    "\n",
    "def test_all(**_params):\n",
    "    _rows, _cols = 4, 3\n",
    "    _f, _axs = plt.subplots(_rows, _cols, figsize=(20, 25))\n",
    "    _f.set_tight_layout(True)\n",
    "    _total: int = 0\n",
    "\n",
    "    for _i, _img_fpath in enumerate(all_images):\n",
    "        _ax = _axs[_i // _cols][_i - (_i // _cols) * _rows]\n",
    "        _fname: str = os.path.basename(_img_fpath)\n",
    "        print(\"Image: \", _fname, end=\"; \")\n",
    "        _bgr: np.ndarray = cv2.imread(_img_fpath)\n",
    "        _, _s, _ = extract_hsv(_bgr)\n",
    "        _blobs: Tuple[cv2.KeyPoint, ...] = detect_blobs(_s, **_params)\n",
    "        _debug_bgr: np.ndarray = draw_blobs(_bgr, _blobs)\n",
    "        _ax.set_title(f\"Image: {_fname}\")\n",
    "        _rgb = cv2.cvtColor(_debug_bgr, cv2.COLOR_BGR2RGB)\n",
    "        _ax.imshow(_rgb)\n",
    "        _total += len(_blobs)\n",
    "    \n",
    "    print(f\"----\\nFound {_total} blobs.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test detector on sample image (using full BGR image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs: Tuple[cv2.KeyPoint, ...] = detect_blobs(sample)\n",
    "debug_img: np.ndarray = draw_blobs(sample, blobs)\n",
    "show_image(debug_img, \"detection on BGR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition: Lit LEDs appear to be saturating the BGR channels of the image\n",
    "\n",
    "Let us take a look at the HSV channels instead of BGR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, s, v = extract_hsv(sample)\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20,10))\n",
    "\n",
    "ax1.set_title(\"Hue\")\n",
    "ax1.imshow(h, cmap = \"gray\")\n",
    "ax2.set_title(\"Saturation\")\n",
    "ax2.imshow(s, cmap = \"gray\")\n",
    "ax3.set_title(\"Value\")\n",
    "ax3.imshow(v, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The Saturation channel appears to have clear peaks (black circles) in the places corresponding to the lit LEDs. Let us try the blob detector on that channel only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test detector on sample image (using Saturation channel from HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, s, _ = extract_hsv(sample)\n",
    "blobs: Tuple[cv2.KeyPoint, ...] = detect_blobs(s)\n",
    "debug_img: np.ndarray = draw_blobs(sample, blobs)\n",
    "show_image(debug_img, \"detection on Saturation channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with the parameters\n",
    "\n",
    "You can pass to the function `detect_blobs()` any parameter from the dictionary `default_parameters` above to replace the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, s, _ = extract_hsv(sample)\n",
    "blobs: Tuple[cv2.KeyPoint, ...] = detect_blobs(\n",
    "    s,\n",
    "    # # ---- generic\n",
    "    minThreshold=10,\n",
    "    # maxThreshold=75,\n",
    "    # thresholdStep=10,\n",
    "    # # ---- filter by area\n",
    "    # filterByArea=True,\n",
    "    # minArea=(8 ** 2) * 3.14,\n",
    "    # maxArea=(64 ** 2) * 3.14,\n",
    "    # # ---- filter by circularity\n",
    "    # filterByCircularity=True,\n",
    "    # minCircularity=0.7,\n",
    "    # # ---- filter by convexity\n",
    "    # filterByConvexity=True,\n",
    "    # minConvexity=0.8,\n",
    "    # # ---- filter by inertia\n",
    "    # filterByInertia=False,\n",
    "    # minInertiaRatio=0.05,\n",
    ")\n",
    "debug_img: np.ndarray = draw_blobs(sample, blobs)\n",
    "show_image(debug_img, \"detection on Saturation channel; minThreshold = 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, s, _ = extract_hsv(sample)\n",
    "blobs: Tuple[cv2.KeyPoint, ...] = detect_blobs(\n",
    "    s,\n",
    "    # # ---- generic\n",
    "    minThreshold=10,\n",
    "    # maxThreshold=75,\n",
    "    # thresholdStep=10,\n",
    "    # # ---- filter by area\n",
    "    # filterByArea=True,\n",
    "    # minArea=(8 ** 2) * 3.14,\n",
    "    # maxArea=(64 ** 2) * 3.14,\n",
    "    # # ---- filter by circularity\n",
    "    # filterByCircularity=True,\n",
    "    minCircularity=0.6,\n",
    "    # # ---- filter by convexity\n",
    "    # filterByConvexity=True,\n",
    "    # minConvexity=0.8,\n",
    "    # # ---- filter by inertia\n",
    "    # filterByInertia=False,\n",
    "    # minInertiaRatio=0.05,\n",
    ")\n",
    "debug_img: np.ndarray = draw_blobs(sample, blobs)\n",
    "show_image(debug_img, \"detection on Saturation channel; minThreshold=10, minCircularity=0.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on the entire train set (with default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on the entire train set (with better parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(\n",
    "    # # ---- generic\n",
    "    minThreshold=10,\n",
    "    # maxThreshold=75,\n",
    "    # thresholdStep=10,\n",
    "    # # ---- filter by area\n",
    "    # filterByArea=True,\n",
    "    # minArea=(8 ** 2) * 3.14,\n",
    "    # maxArea=(64 ** 2) * 3.14,\n",
    "    # # ---- filter by circularity\n",
    "    # filterByCircularity=True,\n",
    "    minCircularity=0.6,\n",
    "    # # ---- filter by convexity\n",
    "    # filterByConvexity=True,\n",
    "    # minConvexity=0.8,\n",
    "    # # ---- filter by inertia\n",
    "    # filterByInertia=False,\n",
    "    # minInertiaRatio=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
